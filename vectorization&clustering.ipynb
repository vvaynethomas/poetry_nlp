{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c762842c-965e-4440-b4e4-086bb214f117",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas(desc=\"progress-bar\")\n",
    "from gensim.models import Doc2Vec\n",
    "from sklearn import utils\n",
    "from sklearn.model_selection import train_test_split\n",
    "import gensim\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from gensim.models.doc2vec import TaggedDocument\n",
    "import re\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9944ae8d-82bf-4ce7-b7fa-4f9858c7c7e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load pickles\n",
    "with open('clean_df.pkl', 'rb') as f:\n",
    "    clean_poem_df = pickle.load(f)\n",
    "    \n",
    "with open('clean_line_df.pkl', 'rb') as g:\n",
    "    clean_line_df = pickle.load(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "939ffbc9-aab3-40d6-8b56-e5738f8489bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>title</th>\n",
       "      <th>content</th>\n",
       "      <th>line</th>\n",
       "      <th>length_in_lines</th>\n",
       "      <th>lexical_diversity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hailey Leithauser</td>\n",
       "      <td>0</td>\n",
       "      <td>Philosophic\\nin its complex, ovoid emptiness,\\...</td>\n",
       "      <td>[philosophic, in its complex ovoid emptiness, ...</td>\n",
       "      <td>15</td>\n",
       "      <td>0.863636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Jody Gladding</td>\n",
       "      <td>1-800-FEAR</td>\n",
       "      <td>We'd  like  to  talk  with  you  about  fear t...</td>\n",
       "      <td>[wed like to talk with you about fear they sai...</td>\n",
       "      <td>11</td>\n",
       "      <td>0.663717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Joseph Brodsky</td>\n",
       "      <td>1 January 1965</td>\n",
       "      <td>The Wise Men will unlearn your name.\\nAbove yo...</td>\n",
       "      <td>[the wise men will unlearn your name, above yo...</td>\n",
       "      <td>24</td>\n",
       "      <td>0.693333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ted Berrigan</td>\n",
       "      <td>3 Pages</td>\n",
       "      <td>For Jack Collom\\n10 Things I do Every Day\\n\\np...</td>\n",
       "      <td>[for jack collom, things i do every day, play ...</td>\n",
       "      <td>26</td>\n",
       "      <td>0.841463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Joe Brainard</td>\n",
       "      <td>30 One-Liners</td>\n",
       "      <td>WINTER\\nMore time is spent at the window.\\n\\nS...</td>\n",
       "      <td>[winter, more time is spent at the window, sum...</td>\n",
       "      <td>65</td>\n",
       "      <td>0.575843</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              author           title  \\\n",
       "1  Hailey Leithauser               0   \n",
       "2      Jody Gladding      1-800-FEAR   \n",
       "3     Joseph Brodsky  1 January 1965   \n",
       "4       Ted Berrigan         3 Pages   \n",
       "5       Joe Brainard   30 One-Liners   \n",
       "\n",
       "                                             content  \\\n",
       "1  Philosophic\\nin its complex, ovoid emptiness,\\...   \n",
       "2  We'd  like  to  talk  with  you  about  fear t...   \n",
       "3  The Wise Men will unlearn your name.\\nAbove yo...   \n",
       "4  For Jack Collom\\n10 Things I do Every Day\\n\\np...   \n",
       "5  WINTER\\nMore time is spent at the window.\\n\\nS...   \n",
       "\n",
       "                                                line  length_in_lines  \\\n",
       "1  [philosophic, in its complex ovoid emptiness, ...               15   \n",
       "2  [wed like to talk with you about fear they sai...               11   \n",
       "3  [the wise men will unlearn your name, above yo...               24   \n",
       "4  [for jack collom, things i do every day, play ...               26   \n",
       "5  [winter, more time is spent at the window, sum...               65   \n",
       "\n",
       "   lexical_diversity  \n",
       "1           0.863636  \n",
       "2           0.663717  \n",
       "3           0.693333  \n",
       "4           0.841463  \n",
       "5           0.575843  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_poem_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "65c51b43-bd38-4c88-9015-81478b20222c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "def prep_list(text):\n",
    "    if isinstance(text, pd.Series):\n",
    "        word_list = word_tokenize(' '.join())\n",
    "    while isinstance(text, list):\n",
    "        text = ' '.join([line for line in text])\n",
    "        word_list = text.split()\n",
    "    else:\n",
    "        word_list = word_tokenize(text)\n",
    "    return word_list\n",
    "\n",
    "clean_poem_df['words'] = clean_poem_df.line.map(prep_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "074f4f90-106e-48bf-b9ab-701e4121e7c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              author           title  \\\n",
      "1  Hailey Leithauser               0   \n",
      "2      Jody Gladding      1-800-FEAR   \n",
      "3     Joseph Brodsky  1 January 1965   \n",
      "4       Ted Berrigan         3 Pages   \n",
      "5       Joe Brainard   30 One-Liners   \n",
      "\n",
      "                                             content  \\\n",
      "1  Philosophic\\nin its complex, ovoid emptiness,\\...   \n",
      "2  We'd  like  to  talk  with  you  about  fear t...   \n",
      "3  The Wise Men will unlearn your name.\\nAbove yo...   \n",
      "4  For Jack Collom\\n10 Things I do Every Day\\n\\np...   \n",
      "5  WINTER\\nMore time is spent at the window.\\n\\nS...   \n",
      "\n",
      "                                                line  length_in_lines  \\\n",
      "1  [philosophic, in its complex ovoid emptiness, ...               15   \n",
      "2  [wed like to talk with you about fear they sai...               11   \n",
      "3  [the wise men will unlearn your name, above yo...               24   \n",
      "4  [for jack collom, things i do every day, play ...               26   \n",
      "5  [winter, more time is spent at the window, sum...               65   \n",
      "\n",
      "   lexical_diversity                                              words  \n",
      "1           0.863636  [philosophic, in, its, complex, ovoid, emptine...  \n",
      "2           0.663717  [wed, like, to, talk, with, you, about, fear, ...  \n",
      "3           0.693333  [the, wise, men, will, unlearn, your, name, ab...  \n",
      "4           0.841463  [for, jack, collom, things, i, do, every, day,...  \n",
      "5           0.575843  [winter, more, time, is, spent, at, the, windo...  \n"
     ]
    }
   ],
   "source": [
    "print(clean_poem_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7f603ca9-41ab-4b71-a717-c1eb43fb272d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tagged_poems = clean_poem_df.apply(lambda x: TaggedDocument(words=x.words, tags=x.author), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "64e4468d-12d6-4e44-8b6b-d89fba87295a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TaggedDocument(words=['philosophic', 'in', 'its', 'complex', 'ovoid', 'emptiness', 'a', 'skillful', 'pundit', 'coined', 'it', 'as', 'a', 'sort', 'of', 'stopgap', 'doorstop', 'for', 'those', 'quaint', 'equations', 'romans', 'never', 'dreamt', 'of', 'in', 'form', 'completely', 'clever', 'and', 'discrete—a', 'mirror', 'come', 'unsilvered', 'loose', 'watch', 'face', 'without', 'the', 'works', 'a', 'hollowed', 'globe', 'from', 'tip', 'to', 'toe', 'unbroken', 'it', 'evades', 'the', 'grappling', 'hooks', 'of', 'mass', 'tilts', 'the', 'thin', 'rim', 'of', 'no', 'thing', 'remains', 'embryonic', 'sum', 'noncogito'], tags='Hailey Leithauser')"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagged_poems.values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fbd6b60d-c08b-4ce1-98b5-862abc998528",
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "cores = multiprocessing.cpu_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9ce6e5a9-b222-48f7-9953-9bdb42916354",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15157/15157 [00:00<00:00, 3031764.31it/s]\n"
     ]
    }
   ],
   "source": [
    "model_dbow = Doc2Vec(dm=0, vector_size=300, negative=5, hs=0, min_count=2, sample = 0, workers=cores)\n",
    "model_dbow.build_vocab([x for x in tqdm(tagged_poems.values)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5d97e8cb-a7d6-41f7-a505-ae291880d8eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15157/15157 [00:00<00:00, 3031619.73it/s]\n",
      "100%|██████████| 15157/15157 [00:00<00:00, 2527153.19it/s]\n",
      "100%|██████████| 15157/15157 [00:00<00:00, 2527153.19it/s]\n",
      "100%|██████████| 15157/15157 [00:00<00:00, 2731975.32it/s]\n",
      "100%|██████████| 15157/15157 [00:00<00:00, 2526349.77it/s]\n",
      "100%|██████████| 15157/15157 [00:00<00:00, 3033500.30it/s]\n",
      "100%|██████████| 15157/15157 [00:00<00:00, 2525647.20it/s]\n",
      "100%|██████████| 15157/15157 [00:00<00:00, 3031041.56it/s]\n",
      "100%|██████████| 15157/15157 [00:00<00:00, 2526149.00it/s]\n",
      "100%|██████████| 15157/15157 [00:00<00:00, 2526249.38it/s]\n",
      "100%|██████████| 15157/15157 [00:00<00:00, 2748511.27it/s]\n",
      "100%|██████████| 15157/15157 [00:00<00:00, 2527153.19it/s]\n",
      "100%|██████████| 15157/15157 [00:00<00:00, 3033789.82it/s]\n",
      "100%|██████████| 15157/15157 [00:00<00:00, 2526048.62it/s]\n",
      "100%|██████████| 15157/15157 [00:00<00:00, 2526149.00it/s]\n",
      "100%|██████████| 15157/15157 [00:00<00:00, 2525847.90it/s]\n",
      "100%|██████████| 15157/15157 [00:00<00:00, 2527253.66it/s]\n",
      "100%|██████████| 15157/15157 [00:00<00:00, 3031041.56it/s]\n",
      "100%|██████████| 15157/15157 [00:00<00:00, 2525747.55it/s]\n",
      "100%|██████████| 15157/15157 [00:00<00:00, 2524844.74it/s]\n",
      "100%|██████████| 15157/15157 [00:00<00:00, 2525145.60it/s]\n",
      "100%|██████████| 15157/15157 [00:00<00:00, 2827857.56it/s]\n",
      "100%|██████████| 15157/15157 [00:00<00:00, 3030752.56it/s]\n",
      "100%|██████████| 15157/15157 [00:00<00:00, 3033210.83it/s]\n",
      "100%|██████████| 15157/15157 [00:00<00:00, 2525245.91it/s]\n",
      "100%|██████████| 15157/15157 [00:00<00:00, 3034079.40it/s]\n",
      "100%|██████████| 15157/15157 [00:00<00:00, 2526450.17it/s]\n",
      "100%|██████████| 15157/15157 [00:00<00:00, 2527153.19it/s]\n",
      "100%|██████████| 15157/15157 [00:00<00:00, 3032342.75it/s]\n",
      "100%|██████████| 15157/15157 [00:00<00:00, 3032632.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 4min 11s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for epoch in range(30):\n",
    "    model_dbow.train(utils.shuffle([x for x in tqdm(tagged_poems.values)]), total_examples=len(tagged_poems.values), epochs=1)\n",
    "    model_dbow.alpha -= 0.002\n",
    "    model_dbow.min_alpha = model_dbow.alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b82ae62-a19e-4ffa-beee-9cf4327e8aef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
