{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "884ae993-7b06-493f-8207-4da568bcbc44",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ccefef3a-bf0c-4c12-987d-058050bc743a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('clean_line_df.pkl', 'rb') as f:\n",
    "    line_df = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5bb6c777-1022-4663-aec7-b59a08e30947",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 485604 entries, 1 to 15651\n",
      "Data columns (total 6 columns):\n",
      " #   Column             Non-Null Count   Dtype   \n",
      "---  ------             --------------   -----   \n",
      " 0   author             485604 non-null  category\n",
      " 1   title              485604 non-null  object  \n",
      " 2   line               485604 non-null  object  \n",
      " 3   words              485604 non-null  object  \n",
      " 4   length_in_words    485604 non-null  int64   \n",
      " 5   lexical_diversity  485604 non-null  float64 \n",
      "dtypes: category(1), float64(1), int64(1), object(3)\n",
      "memory usage: 23.2+ MB\n"
     ]
    }
   ],
   "source": [
    "line_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d25b955f-2339-4b1b-9f56-8d028365da5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_lines = line_df.line.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e17cc18e-b2ff-4456-9e42-4fd4fa75aea5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['philosophic',\n",
       " 'in its complex ovoid emptiness',\n",
       " 'a skillful pundit coined it as a sort',\n",
       " 'of stopgap doorstop for those',\n",
       " 'quaint equations',\n",
       " 'romans never',\n",
       " 'dreamt of in form completely clever',\n",
       " 'and discreteâ€”a mirror come unsilvered',\n",
       " 'loose watch face without the works',\n",
       " 'a hollowed globe']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_lines[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aa2522e-7494-4282-8e07-412aa9dd6b24",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f34c33fa-22d0-4ac8-8485-e1facb4dd622",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "485604\n",
      "philosophic\n"
     ]
    }
   ],
   "source": [
    "print(len(corpus_lines))\n",
    "print(corpus_lines[0])\n",
    "corpus_string = ' '.join(corpus_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bd52f2cf-e418-4eb4-950a-3738f1c81cb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "121325\n"
     ]
    }
   ],
   "source": [
    "tokenizer = Tokenizer(num_words=5000)\n",
    "tokenizer.fit_on_texts(corpus_lines)\n",
    "# input_sequences = tokenizer.texts_to_sequences(corpus_lines)\n",
    "total_words = len(tokenizer.word_index) + 1\n",
    "print(total_words)\n",
    "input_sequences = []\n",
    "for line in corpus_lines:\n",
    "    token_list = tokenizer.texts_to_sequences([line])[0]\n",
    "    for i in range(1, len(token_list)):\n",
    "        n_gram_sequence = token_list[:i+1]\n",
    "        input_sequences.append(n_gram_sequence)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b804367-96f6-49d2-8d0e-ddc91c7e0935",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3a839c76-c1ca-44b9-ab85-9526fe573b90",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_sequence_length = max([len(x) for x in input_sequences])\n",
    "input_sequences = np.array(pad_sequences(input_sequences, maxlen=max_sequence_length, padding='pre'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0decc97d-9be1-4ac4-a1cc-ac2e55ac7ffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "xs, labels = input_sequences[:,:-1],input_sequences[:,-1]\n",
    "ys = tf.keras.utils.to_categorical(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8049c48f-7d55-4d15-aca5-ef1bb8334cbd",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "only size-1 arrays can be converted to Python scalars",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-19-b6dc19822f21>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDropout\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0.1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mDense\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtotal_words\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mDense\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'softmax'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\core.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, units, activation, use_bias, kernel_initializer, bias_initializer, kernel_regularizer, bias_regularizer, activity_regularizer, kernel_constraint, bias_constraint, **kwargs)\u001b[0m\n\u001b[0;32m   1144\u001b[0m         activity_regularizer=activity_regularizer, **kwargs)\n\u001b[0;32m   1145\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1146\u001b[1;33m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munits\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0munits\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0munits\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0munits\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1147\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mactivation\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mactivations\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mactivation\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1148\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muse_bias\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0muse_bias\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: only size-1 arrays can be converted to Python scalars"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(total_words, 80, input_length=max_sequence_length-1))\n",
    "model.add(LSTM(100, return_sequences=True))\n",
    "model.add(LSTM(50))\n",
    "model.add(tf.keras.layers.Dropout(0.1))\n",
    "model.add(Dense(total_words/20))\n",
    "model.add(Dense(total_words, activation='softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1b0bb64-3a9e-41e4-a2de-b62559857a73",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
