{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "45ea39d4-4080-41eb-a0e6-3e9eda83c481",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.tokenize import RegexpTokenizer, sent_tokenize, word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tag import pos_tag, map_tag\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a32ed17d-0347-46a4-b98e-18ae89172746",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 15652 entries, 0 to 15651\n",
      "Data columns (total 5 columns):\n",
      " #   Column                Non-Null Count  Dtype   \n",
      "---  ------                --------------  -----   \n",
      " 0   unnamed: 0            15652 non-null  int64   \n",
      " 1   author                15652 non-null  category\n",
      " 2   title                 15652 non-null  object  \n",
      " 3   poetry foundation id  15652 non-null  int64   \n",
      " 4   content               15652 non-null  object  \n",
      "dtypes: category(1), int64(2), object(2)\n",
      "memory usage: 674.7+ KB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 15652 entries, 0 to 15651\n",
      "Data columns (total 3 columns):\n",
      " #   Column   Non-Null Count  Dtype   \n",
      "---  ------   --------------  -----   \n",
      " 0   author   15652 non-null  category\n",
      " 1   title    15652 non-null  object  \n",
      " 2   content  15652 non-null  object  \n",
      "dtypes: category(1), object(2)\n",
      "memory usage: 430.2+ KB\n"
     ]
    }
   ],
   "source": [
    "pf_df = pd.read_csv('kaggle_poem_dataset.csv')\n",
    "pf_df['Author'] = pf_df.Author.astype('category')\n",
    "pf_df.columns = [name.lower() for name in pf_df.columns]\n",
    "pf_df.info()\n",
    "pf_df = pf_df.drop(['unnamed: 0', 'poetry foundation id'], axis=1)\n",
    "pf_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0077e769-8d54-43ce-a8a1-2edaa9e24696",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create function to clean lines\n",
    "import string, re\n",
    "from nltk.corpus import words\n",
    "import multiprocessing as mp\n",
    "def clean_text(text):\n",
    "    cont_dict = { \n",
    "        \"ain't\": \"am not / are not / is not / has not / have not\",\n",
    "        \"aren't\": \"are not / am not\",\n",
    "        \"can't\": \"cannot\",\n",
    "        \"can't've\": \"cannot have\",\n",
    "        \"'cause\": \"because\",\n",
    "        \"could've\": \"could have\",\n",
    "        \"couldn't\": \"could not\",\n",
    "        \"couldn't've\": \"could not have\",\n",
    "        \"didn't\": \"did not\",\n",
    "        \"doesn't\": \"does not\",\n",
    "        \"don't\": \"do not\",\n",
    "        \"hadn't\": \"had not\",\n",
    "        \"hadn't've\": \"had not have\",\n",
    "        \"hasn't\": \"has not\",\n",
    "        \"haven't\": \"have not\",\n",
    "        \"he'd\": \"he had / he would\",\n",
    "        \"he'd've\": \"he would have\",\n",
    "        \"he'll\": \"he shall / he will\",\n",
    "        \"he'll've\": \"he shall have / he will have\",\n",
    "        \"he's\": \"he has / he is\",\n",
    "        \"how'd\": \"how did\",\n",
    "        \"how'd'y\": \"how do you\",\n",
    "        \"how'll\": \"how will\",\n",
    "        \"how's\": \"how has / how is / how does\",\n",
    "        \"I'd\": \"I had / I would\",\n",
    "        \"I'd've\": \"I would have\",\n",
    "        \"I'll\": \"I shall / I will\",\n",
    "        \"I'll've\": \"I shall have / I will have\",\n",
    "        \"I'm\": \"I am\",\n",
    "        \"I've\": \"I have\",\n",
    "        \"isn't\": \"is not\",\n",
    "        \"it'd\": \"it had / it would\",\n",
    "        \"it'd've\": \"it would have\",\n",
    "        \"it'll\": \"it shall / it will\",\n",
    "        \"it'll've\": \"it shall have / it will have\",\n",
    "        \"it's\": \"it has / it is\",\n",
    "        \"let's\": \"let us\",\n",
    "        \"ma'am\": \"madam\",\n",
    "        \"mayn't\": \"may not\",\n",
    "        \"might've\": \"might have\",\n",
    "        \"mightn't\": \"might not\",\n",
    "        \"mightn't've\": \"might not have\",\n",
    "        \"must've\": \"must have\",\n",
    "        \"mustn't\": \"must not\",\n",
    "        \"mustn't've\": \"must not have\",\n",
    "        \"needn't\": \"need not\",\n",
    "        \"needn't've\": \"need not have\",\n",
    "        \"o'clock\": \"of the clock\",\n",
    "        \"oughtn't\": \"ought not\",\n",
    "        \"oughtn't've\": \"ought not have\",\n",
    "        \"shan't\": \"shall not\",\n",
    "        \"sha'n't\": \"shall not\",\n",
    "        \"shan't've\": \"shall not have\",\n",
    "        \"she'd\": \"she had / she would\",\n",
    "        \"she'd've\": \"she would have\",\n",
    "        \"she'll\": \"she shall / she will\",\n",
    "        \"she'll've\": \"she shall have / she will have\",\n",
    "        \"she's\": \"she has / she is\",\n",
    "        \"should've\": \"should have\",\n",
    "        \"shouldn't\": \"should not\",\n",
    "        \"shouldn't've\": \"should not have\",\n",
    "        \"so've\": \"so have\",\n",
    "        \"so's\": \"so as / so is\",\n",
    "        \"that'd\": \"that would / that had\",\n",
    "        \"that'd've\": \"that would have\",\n",
    "        \"that's\": \"that has / that is\",\n",
    "        \"there'd\": \"there had / there would\",\n",
    "        \"there'd've\": \"there would have\",\n",
    "        \"there's\": \"there has / there is\",\n",
    "        \"they'd\": \"they had / they would\",\n",
    "        \"they'd've\": \"they would have\",\n",
    "        \"they'll\": \"they shall / they will\",\n",
    "        \"they'll've\": \"they shall have / they will have\",\n",
    "        \"they're\": \"they are\",\n",
    "        \"they've\": \"they have\",\n",
    "        \"to've\": \"to have\",\n",
    "        \"wasn't\": \"was not\",\n",
    "        \"we'd\": \"we had / we would\",\n",
    "        \"we'd've\": \"we would have\",\n",
    "        \"we'll\": \"we will\",\n",
    "        \"we'll've\": \"we will have\",\n",
    "        \"we're\": \"we are\",\n",
    "        \"we've\": \"we have\",\n",
    "        \"weren't\": \"were not\",\n",
    "        \"what'll\": \"what shall / what will\",\n",
    "        \"what'll've\": \"what shall have / what will have\",\n",
    "        \"what're\": \"what are\",\n",
    "        \"what's\": \"what has / what is\",\n",
    "        \"what've\": \"what have\",\n",
    "        \"when's\": \"when has / when is\",\n",
    "        \"when've\": \"when have\",\n",
    "        \"where'd\": \"where did\",\n",
    "        \"where's\": \"where has / where is\",\n",
    "        \"where've\": \"where have\",\n",
    "        \"who'll\": \"who shall / who will\",\n",
    "        \"who'll've\": \"who shall have / who will have\",\n",
    "        \"who's\": \"who has / who is\",\n",
    "        \"who've\": \"who have\",\n",
    "        \"why's\": \"why has / why is\",\n",
    "        \"why've\": \"why have\",\n",
    "        \"will've\": \"will have\",\n",
    "        \"won't\": \"will not\",\n",
    "        \"won't've\": \"will not have\",\n",
    "        \"would've\": \"would have\",\n",
    "        \"wouldn't\": \"would not\",\n",
    "        \"wouldn't've\": \"would not have\",\n",
    "        \"y'all\": \"you all\",\n",
    "        \"y'all'd\": \"you all would\",\n",
    "        \"y'all'd've\": \"you all would have\",\n",
    "        \"y'all're\": \"you all are\",\n",
    "        \"y'all've\": \"you all have\",\n",
    "        \"you'd\": \"you had / you would\",\n",
    "        \"you'd've\": \"you would have\",\n",
    "        \"you'll\": \"you shall / you will\",\n",
    "        \"you'll've\": \"you shall have / you will have\",\n",
    "        \"you're\": \"you are\",\n",
    "        \"you've\": \"you have\"\n",
    "        }\n",
    "\n",
    "#     stopwords_list = stopwords.words(\"english\")\n",
    "    try:\n",
    "        text = text.lower()\n",
    "        for word in cont_dict.keys():\n",
    "            pattern = re.compile(f'({str(word)})',re.I)\n",
    "            text = pattern.sub(cont_dict[word],text)\n",
    "        tokens = text.split()\n",
    "#         text = ' '.join([word for word in tokens if word not in stopwords_list])\n",
    "        text = ' '.join([''.join([c if c.isalnum() else ' ' for c in word]) for word in tokens])\n",
    "        text = re.sub(' +', ' ', text)\n",
    "        text = text.replace('\\%','')\n",
    "        text = re.sub('\\[.*?\\]', '', text)\n",
    "        text = re.sub('https?://\\S+|www\\.\\S+', '', text)\n",
    "        text = re.sub('<.*?>+', '', text)\n",
    "        text = re.sub('[%s]' % re.escape(string.punctuation), '', text)\n",
    "        text = re.sub('\\n', ' ', text)\n",
    "        text = re.sub('\\w*\\d\\w*', '', text)\n",
    "        text = \" \".join(filter(lambda x:x[0]!=\"@\", tokens))\n",
    "        return text.strip()\n",
    "    \n",
    "    except AttributeError:\n",
    "        text = str(text)\n",
    "        return clean_text(text)\n",
    "    \n",
    "    except TypeError:\n",
    "        text = text.decode()[1:]\n",
    "        return clean_list(text.strip())\n",
    "    return text\n",
    "\n",
    "def clean_list(list_of_strings):\n",
    "    return [clean_text(string) for string in list_of_strings]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da91d8c0-e252-4238-979f-57cadba314fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create column to store document as list of lines\n",
    "import multiprocessing as mp\n",
    "pf_df['line'] = pf_df.content.str.split('\\n')\n",
    "with mp.Pool(processes=mp.cpu_count()-1) as pool:\n",
    "    clean_lines = pool.map(clean_list, pf_df.line)\n",
    "# pf_df['line'] = pf_df.line.map(clean_list)\n",
    "pf_df['line'] = clean_lines\n",
    "print(pf_df.iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "454aa542-89ef-4caf-9c82-b545553d8ede",
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct function to remove empty lines for accurate line count\n",
    "def remove_empty_lines(list_of_lines):\n",
    "    try:\n",
    "        return [i for i in list_of_lines if i]\n",
    "    except TypeError:\n",
    "        return pd.NA\n",
    "    \n",
    "pf_df['line'] = pf_df.line.map(remove_empty_lines)\n",
    "print(pf_df.iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a604dd98-0604-46c5-a99b-356399bf4367",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create column for length of poem in lines\n",
    "pf_df['length_in_lines'] = pf_df.line.map(len)\n",
    "pf_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db179295-3503-4ffa-a100-c77da7ff24d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.displot(pf_df.length_in_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f99f54b-4d9a-4ba6-b1d6-818499aa5c1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filtering outliers with zscore\n",
    "from scipy import stats\n",
    "clean_df = pf_df[(np.abs(stats.zscore(pf_df.length_in_lines)) < 2.5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12ba4d5d-c6f9-48fa-951d-40ad71624897",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter sub-haiku length works\n",
    "clean_df = clean_df[clean_df.length_in_lines > 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1d8b40d-b90d-4cde-9ed2-35ee5eac2f08",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.displot(clean_df.length_in_lines, kde=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ff434b9-7c33-4011-bd96-67ba61928f9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lexical_diversity(line_list):\n",
    "    doc_string = ' '.join(line_list)\n",
    "    words = word_tokenize(doc_string)\n",
    "    return (len(set(words))/len(words))\n",
    "        \n",
    "clean_df['lexical_diversity'] = clean_df.line.map(lexical_diversity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bd89af6-54d5-491f-91d5-fb1c59c3435a",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df.head()\n",
    "with open('clean_df.pkl', 'wb') as f:\n",
    "    pickle.dump(clean_df, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24c678d4-0100-4759-a1c2-44227ee2dfa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.displot(clean_df.lexical_diversity, kde=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a0b822e-b7d6-4778-87de-64911ed34804",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample 3 lines from each poem\n",
    "# import random\n",
    "# clean_df.line.describe()\n",
    "# docs_in_lines = clean_df.line.to_list()\n",
    "# line_samples = [random.sample(lines,3) for lines in docs_in_lines]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f02199da-a0ee-4b9b-99e4-7c3852693d28",
   "metadata": {},
   "outputs": [],
   "source": [
    "line_df = clean_df.explode('line').drop(['length_in_lines', 'content','lexical_diversity'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79da3079-33b3-4195-9e36-b123d55db688",
   "metadata": {},
   "outputs": [],
   "source": [
    "line_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83b4086d-0f66-42cf-aa5b-9ab9fec69ef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "line_df['words'] = line_df.line.map(word_tokenize)\n",
    "line_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a64053a-567b-438d-b5c8-4861c97cb420",
   "metadata": {},
   "outputs": [],
   "source": [
    "line_df['length_in_words'] = line_df.words.map(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78a6b9a5-e73c-4528-be9c-8b9545f7d111",
   "metadata": {},
   "outputs": [],
   "source": [
    "line_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f69ce3c-9ce0-4dc5-826b-f237304f713b",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = line_df.length_in_words\n",
    "sns.displot(x, kde=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c67e0a87-530b-4d9c-a073-4aaa4c8f4684",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filtering outliers with zscore\n",
    "from scipy import stats\n",
    "clean_line_df = line_df[(np.abs(stats.zscore(line_df.length_in_words)) < 2.5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eac5f5bf-5210-4bd1-9559-d54b5e990e49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, ax = plt.subplots()\n",
    "x = clean_line_df.length_in_words\n",
    "sns.displot(x, kde=True)\n",
    "# plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3e56e7b-10e3-460b-ae97-220f4e18e5f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "line_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc92192c-ff1f-4e89-8609-59df099559a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_line_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f6a7596-db38-4003-9ca9-038b2f5924ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_line_df['lexical_diversity'] = clean_line_df.words.map(lexical_diversity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5856146-c98c-49fb-8b09-72762a3f8878",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_line_df.head()\n",
    "with open('clean_line_df.pkl', 'wb') as f:\n",
    "    pickle.dump(clean_line_df, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "471c77dd-5598-4257-b11c-413e7338d14b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.displot(clean_line_df.lexical_diversity, kde=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eadc3a38-6100-419b-8cbb-1c7822a2f6d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "author_line_lexical = clean_line_df.drop(['title','line','words'], axis=1).groupby('author').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfa7b121-ffdc-433f-a520-e314d9d7ce80",
   "metadata": {},
   "outputs": [],
   "source": [
    "author_line_lexical.reset_index(inplace=True)\n",
    "sns.displot(data=author_line_lexical, x='length_in_words',y='lexical_diversity')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e31aaed9-9aab-4955-98c7-d375f4d259f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "author_line_lexical.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10c91144-69b3-416e-a459-de5d6d9e9109",
   "metadata": {},
   "outputs": [],
   "source": [
    "# author_line_lexical_mode = clean_line_df.drop(['title','line','words'], axis=1).groupby('author').mode()\n",
    "# author_line_lexical_mode.reset_index(inplace=True)\n",
    "# sns.displot(data=author_line_lexical_avg, x='length_in_words',y='lexical_diversity')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1298e5c9-dd59-4ff3-994d-b12c1805495a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f66785aa-32f6-493c-97af-37b00df544a1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
