{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "884ae993-7b06-493f-8207-4da568bcbc44",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ccefef3a-bf0c-4c12-987d-058050bc743a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('clean_line_df.pkl', 'rb') as f:\n",
    "    line_df = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5bb6c777-1022-4663-aec7-b59a08e30947",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 485604 entries, 1 to 15651\n",
      "Data columns (total 6 columns):\n",
      " #   Column             Non-Null Count   Dtype   \n",
      "---  ------             --------------   -----   \n",
      " 0   author             485604 non-null  category\n",
      " 1   title              485604 non-null  object  \n",
      " 2   line               485604 non-null  object  \n",
      " 3   words              485604 non-null  object  \n",
      " 4   length_in_words    485604 non-null  int64   \n",
      " 5   lexical_diversity  485604 non-null  float64 \n",
      "dtypes: category(1), float64(1), int64(1), object(3)\n",
      "memory usage: 23.2+ MB\n"
     ]
    }
   ],
   "source": [
    "line_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d25b955f-2339-4b1b-9f56-8d028365da5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_lines = line_df.line.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e17cc18e-b2ff-4456-9e42-4fd4fa75aea5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['philosophic',\n",
       " 'in its complex ovoid emptiness',\n",
       " 'a skillful pundit coined it as a sort',\n",
       " 'of stopgap doorstop for those',\n",
       " 'quaint equations',\n",
       " 'romans never',\n",
       " 'dreamt of in form completely clever',\n",
       " 'and discreteâ€”a mirror come unsilvered',\n",
       " 'loose watch face without the works',\n",
       " 'a hollowed globe']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_lines[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aa2522e-7494-4282-8e07-412aa9dd6b24",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f34c33fa-22d0-4ac8-8485-e1facb4dd622",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "485604\n",
      "philosophic\n"
     ]
    }
   ],
   "source": [
    "print(len(corpus_lines))\n",
    "print(corpus_lines[0])\n",
    "corpus_string = ' '.join(corpus_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bd52f2cf-e418-4eb4-950a-3738f1c81cb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "121325\n"
     ]
    }
   ],
   "source": [
    "tokenizer = Tokenizer(num_words=5000)\n",
    "tokenizer.fit_on_texts(corpus_lines)\n",
    "# input_sequences = tokenizer.texts_to_sequences(corpus_lines)\n",
    "total_words = len(tokenizer.word_index) + 1\n",
    "print(total_words)\n",
    "input_sequences = []\n",
    "for line in corpus_lines:\n",
    "    token_list = tokenizer.texts_to_sequences([line])[0]\n",
    "    for i in range(1, len(token_list)):\n",
    "        n_gram_sequence = token_list[:i+1]\n",
    "        input_sequences.append(n_gram_sequence)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b804367-96f6-49d2-8d0e-ddc91c7e0935",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3a839c76-c1ca-44b9-ab85-9526fe573b90",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_sequence_length = max([len(x) for x in input_sequences])\n",
    "input_sequences = np.array(pad_sequences(input_sequences, maxlen=max_sequence_length, padding='pre'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0decc97d-9be1-4ac4-a1cc-ac2e55ac7ffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "xs, labels = input_sequences[:,:-1],input_sequences[:,-1]\n",
    "ys = tf.keras.utils.to_categorical(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8049c48f-7d55-4d15-aca5-ef1bb8334cbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(total_words, 80, input_length=max_sequence_length-1))\n",
    "model.add(LSTM(100, return_sequences=True))\n",
    "model.add(LSTM(50))\n",
    "model.add(tf.keras.layers.Dropout(0.1))\n",
    "model.add(Dense(total_words/20))\n",
    "model.add(Dense(total_words, activation='softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1b0bb64-3a9e-41e4-a2de-b62559857a73",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
