{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'wordcloud'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-aa0e9b1ccaef>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msys\u001b[0m\u001b[1;33m;\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmultiprocessing\u001b[0m\u001b[1;33m;\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mwordcloud\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mWordCloud\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mImageColorGenerator\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m;\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mitertools\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcycle\u001b[0m\u001b[1;33m;\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'wordcloud'"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.feature_extraction import text\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.cluster import KMeans\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from sklearn.neighbors import KDTree;\n",
    "import os;\n",
    "import re;\n",
    "import logging;\n",
    "import sqlite3;\n",
    "import time;\n",
    "import sys;\n",
    "import multiprocessing;\n",
    "from wordcloud import WordCloud, ImageColorGenerator\n",
    "import matplotlib.pyplot as plt;\n",
    "from itertools import cycle;\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1989 entries, 0 to 1988\n",
      "Data columns (total 27 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   Date    1989 non-null   object\n",
      " 1   Label   1989 non-null   int64 \n",
      " 2   Top1    1989 non-null   object\n",
      " 3   Top2    1989 non-null   object\n",
      " 4   Top3    1989 non-null   object\n",
      " 5   Top4    1989 non-null   object\n",
      " 6   Top5    1989 non-null   object\n",
      " 7   Top6    1989 non-null   object\n",
      " 8   Top7    1989 non-null   object\n",
      " 9   Top8    1989 non-null   object\n",
      " 10  Top9    1989 non-null   object\n",
      " 11  Top10   1989 non-null   object\n",
      " 12  Top11   1989 non-null   object\n",
      " 13  Top12   1989 non-null   object\n",
      " 14  Top13   1989 non-null   object\n",
      " 15  Top14   1989 non-null   object\n",
      " 16  Top15   1989 non-null   object\n",
      " 17  Top16   1989 non-null   object\n",
      " 18  Top17   1989 non-null   object\n",
      " 19  Top18   1989 non-null   object\n",
      " 20  Top19   1989 non-null   object\n",
      " 21  Top20   1989 non-null   object\n",
      " 22  Top21   1989 non-null   object\n",
      " 23  Top22   1989 non-null   object\n",
      " 24  Top23   1988 non-null   object\n",
      " 25  Top24   1986 non-null   object\n",
      " 26  Top25   1986 non-null   object\n",
      "dtypes: int64(1), object(26)\n",
      "memory usage: 419.7+ KB\n"
     ]
    }
   ],
   "source": [
    "text_stock_df = pd.read_csv('kaggle_poem_dataset.csv')\n",
    "# text_stock_df = text_stock_df.set_index('Date')\n",
    "text_stock_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Date', 'Label', 'Top1', 'Top2', 'Top3', 'Top4', 'Top5', 'Top6', 'Top7',\n",
      "       'Top8', 'Top9', 'Top10', 'Top11', 'Top12', 'Top13', 'Top14', 'Top15',\n",
      "       'Top16', 'Top17', 'Top18', 'Top19', 'Top20', 'Top21', 'Top22', 'Top23',\n",
      "       'Top24', 'Top25'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "X = text_stock_df.copy()\n",
    "sns.countplot(y=X.Label)\n",
    "# y = X.pop('Label')\n",
    "# X = X.apply(lambda x: x.astype('category'))\n",
    "print(X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0  Date                                            2008-08-08\n",
      "   Label                                                    0\n",
      "   Top1     b\"Georgia 'downs two Russian warplanes' as cou...\n",
      "   Top2               b'BREAKING: Musharraf to be impeached.'\n",
      "   Top3     b'Russia Today: Columns of troops roll into So...\n",
      "dtype: object\n",
      "53696\n"
     ]
    }
   ],
   "source": [
    "# clean and stack ngram\n",
    "stacked_ngrams = X.stack()\n",
    "print(stacked_ngrams.head())\n",
    "ngrams = stacked_ngrams.values\n",
    "print(len(list(ngrams)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Label</th>\n",
       "      <th>variable</th>\n",
       "      <th>Ngram</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2008-08-08</td>\n",
       "      <td>0</td>\n",
       "      <td>Top1</td>\n",
       "      <td>b\"Georgia 'downs two Russian warplanes' as cou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2008-08-11</td>\n",
       "      <td>1</td>\n",
       "      <td>Top1</td>\n",
       "      <td>b'Why wont America and Nato help us? If they w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2008-08-12</td>\n",
       "      <td>0</td>\n",
       "      <td>Top1</td>\n",
       "      <td>b'Remember that adorable 9-year-old who sang a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2008-08-13</td>\n",
       "      <td>0</td>\n",
       "      <td>Top1</td>\n",
       "      <td>b' U.S. refuses Israel weapons to attack Iran:...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2008-08-14</td>\n",
       "      <td>1</td>\n",
       "      <td>Top1</td>\n",
       "      <td>b'All the experts admit that we should legalis...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date  Label variable  \\\n",
       "0  2008-08-08      0     Top1   \n",
       "1  2008-08-11      1     Top1   \n",
       "2  2008-08-12      0     Top1   \n",
       "3  2008-08-13      0     Top1   \n",
       "4  2008-08-14      1     Top1   \n",
       "\n",
       "                                               Ngram  \n",
       "0  b\"Georgia 'downs two Russian warplanes' as cou...  \n",
       "1  b'Why wont America and Nato help us? If they w...  \n",
       "2  b'Remember that adorable 9-year-old who sang a...  \n",
       "3  b' U.S. refuses Israel weapons to attack Iran:...  \n",
       "4  b'All the experts admit that we should legalis...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# X_pivot = X.pivot(index='Date', columns=X.columns)\n",
    "# X_pivot.melt(id_vars=['Label'], value_vars=X_pivo)\n",
    "X_melt = pd.melt(X,id_vars=['Date','Label'], value_name='Ngram')\n",
    "X_melt.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>label</th>\n",
       "      <th>ngram</th>\n",
       "      <th>top_n</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2008-08-08</td>\n",
       "      <td>0</td>\n",
       "      <td>b\"Georgia 'downs two Russian warplanes' as cou...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2008-08-11</td>\n",
       "      <td>1</td>\n",
       "      <td>b'Why wont America and Nato help us? If they w...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2008-08-12</td>\n",
       "      <td>0</td>\n",
       "      <td>b'Remember that adorable 9-year-old who sang a...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2008-08-13</td>\n",
       "      <td>0</td>\n",
       "      <td>b' U.S. refuses Israel weapons to attack Iran:...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2008-08-14</td>\n",
       "      <td>1</td>\n",
       "      <td>b'All the experts admit that we should legalis...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date  label                                              ngram  top_n\n",
       "0  2008-08-08      0  b\"Georgia 'downs two Russian warplanes' as cou...      0\n",
       "1  2008-08-11      1  b'Why wont America and Nato help us? If they w...      0\n",
       "2  2008-08-12      0  b'Remember that adorable 9-year-old who sang a...      0\n",
       "3  2008-08-13      0  b' U.S. refuses Israel weapons to attack Iran:...      0\n",
       "4  2008-08-14      1  b'All the experts admit that we should legalis...      0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import preprocessing as skpp\n",
    "le = skpp.LabelEncoder().fit(X_melt['variable'])\n",
    "top_encoded = le.transform(X_melt['variable'])\n",
    "X_melt['top_n']= top_encoded\n",
    "X_melt = X_melt.drop('variable', axis=1)\n",
    "X_melt.head()\n",
    "X_melt.columns = [i.lower() for i in X_melt.columns]\n",
    "X_melt.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "like bats like 39 2 hats\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import html\n",
    "import string\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "def preprocess_text(text):\n",
    "    cont_dict = { \n",
    "        \"ain't\": \"am not / are not / is not / has not / have not\",\n",
    "        \"aren't\": \"are not / am not\",\n",
    "        \"can't\": \"cannot\",\n",
    "        \"can't've\": \"cannot have\",\n",
    "        \"'cause\": \"because\",\n",
    "        \"could've\": \"could have\",\n",
    "        \"couldn't\": \"could not\",\n",
    "        \"couldn't've\": \"could not have\",\n",
    "        \"didn't\": \"did not\",\n",
    "        \"doesn't\": \"does not\",\n",
    "        \"don't\": \"do not\",\n",
    "        \"hadn't\": \"had not\",\n",
    "        \"hadn't've\": \"had not have\",\n",
    "        \"hasn't\": \"has not\",\n",
    "        \"haven't\": \"have not\",\n",
    "        \"he'd\": \"he had / he would\",\n",
    "        \"he'd've\": \"he would have\",\n",
    "        \"he'll\": \"he shall / he will\",\n",
    "        \"he'll've\": \"he shall have / he will have\",\n",
    "        \"he's\": \"he has / he is\",\n",
    "        \"how'd\": \"how did\",\n",
    "        \"how'd'y\": \"how do you\",\n",
    "        \"how'll\": \"how will\",\n",
    "        \"how's\": \"how has / how is / how does\",\n",
    "        \"I'd\": \"I had / I would\",\n",
    "        \"I'd've\": \"I would have\",\n",
    "        \"I'll\": \"I shall / I will\",\n",
    "        \"I'll've\": \"I shall have / I will have\",\n",
    "        \"I'm\": \"I am\",\n",
    "        \"I've\": \"I have\",\n",
    "        \"isn't\": \"is not\",\n",
    "        \"it'd\": \"it had / it would\",\n",
    "        \"it'd've\": \"it would have\",\n",
    "        \"it'll\": \"it shall / it will\",\n",
    "        \"it'll've\": \"it shall have / it will have\",\n",
    "        \"it's\": \"it has / it is\",\n",
    "        \"let's\": \"let us\",\n",
    "        \"ma'am\": \"madam\",\n",
    "        \"mayn't\": \"may not\",\n",
    "        \"might've\": \"might have\",\n",
    "        \"mightn't\": \"might not\",\n",
    "        \"mightn't've\": \"might not have\",\n",
    "        \"must've\": \"must have\",\n",
    "        \"mustn't\": \"must not\",\n",
    "        \"mustn't've\": \"must not have\",\n",
    "        \"needn't\": \"need not\",\n",
    "        \"needn't've\": \"need not have\",\n",
    "        \"o'clock\": \"of the clock\",\n",
    "        \"oughtn't\": \"ought not\",\n",
    "        \"oughtn't've\": \"ought not have\",\n",
    "        \"shan't\": \"shall not\",\n",
    "        \"sha'n't\": \"shall not\",\n",
    "        \"shan't've\": \"shall not have\",\n",
    "        \"she'd\": \"she had / she would\",\n",
    "        \"she'd've\": \"she would have\",\n",
    "        \"she'll\": \"she shall / she will\",\n",
    "        \"she'll've\": \"she shall have / she will have\",\n",
    "        \"she's\": \"she has / she is\",\n",
    "        \"should've\": \"should have\",\n",
    "        \"shouldn't\": \"should not\",\n",
    "        \"shouldn't've\": \"should not have\",\n",
    "        \"so've\": \"so have\",\n",
    "        \"so's\": \"so as / so is\",\n",
    "        \"that'd\": \"that would / that had\",\n",
    "        \"that'd've\": \"that would have\",\n",
    "        \"that's\": \"that has / that is\",\n",
    "        \"there'd\": \"there had / there would\",\n",
    "        \"there'd've\": \"there would have\",\n",
    "        \"there's\": \"there has / there is\",\n",
    "        \"they'd\": \"they had / they would\",\n",
    "        \"they'd've\": \"they would have\",\n",
    "        \"they'll\": \"they shall / they will\",\n",
    "        \"they'll've\": \"they shall have / they will have\",\n",
    "        \"they're\": \"they are\",\n",
    "        \"they've\": \"they have\",\n",
    "        \"to've\": \"to have\",\n",
    "        \"wasn't\": \"was not\",\n",
    "        \"we'd\": \"we had / we would\",\n",
    "        \"we'd've\": \"we would have\",\n",
    "        \"we'll\": \"we will\",\n",
    "        \"we'll've\": \"we will have\",\n",
    "        \"we're\": \"we are\",\n",
    "        \"we've\": \"we have\",\n",
    "        \"weren't\": \"were not\",\n",
    "        \"what'll\": \"what shall / what will\",\n",
    "        \"what'll've\": \"what shall have / what will have\",\n",
    "        \"what're\": \"what are\",\n",
    "        \"what's\": \"what has / what is\",\n",
    "        \"what've\": \"what have\",\n",
    "        \"when's\": \"when has / when is\",\n",
    "        \"when've\": \"when have\",\n",
    "        \"where'd\": \"where did\",\n",
    "        \"where's\": \"where has / where is\",\n",
    "        \"where've\": \"where have\",\n",
    "        \"who'll\": \"who shall / who will\",\n",
    "        \"who'll've\": \"who shall have / who will have\",\n",
    "        \"who's\": \"who has / who is\",\n",
    "        \"who've\": \"who have\",\n",
    "        \"why's\": \"why has / why is\",\n",
    "        \"why've\": \"why have\",\n",
    "        \"will've\": \"will have\",\n",
    "        \"won't\": \"will not\",\n",
    "        \"won't've\": \"will not have\",\n",
    "        \"would've\": \"would have\",\n",
    "        \"wouldn't\": \"would not\",\n",
    "        \"wouldn't've\": \"would not have\",\n",
    "        \"y'all\": \"you all\",\n",
    "        \"y'all'd\": \"you all would\",\n",
    "        \"y'all'd've\": \"you all would have\",\n",
    "        \"y'all're\": \"you all are\",\n",
    "        \"y'all've\": \"you all have\",\n",
    "        \"you'd\": \"you had / you would\",\n",
    "        \"you'd've\": \"you would have\",\n",
    "        \"you'll\": \"you shall / you will\",\n",
    "        \"you'll've\": \"you shall have / you will have\",\n",
    "        \"you're\": \"you are\",\n",
    "        \"you've\": \"you have\"\n",
    "        }\n",
    "\n",
    "    stopwords_list = stopwords.words(\"english\")\n",
    "    try:\n",
    "        while text.startswith('b'):\n",
    "            text = text[1:]\n",
    "        text = text.lower()\n",
    "        for word in cont_dict.keys():\n",
    "            pattern = re.compile(f'({str(word)})',re.I)\n",
    "            text = pattern.sub(cont_dict[word],text)\n",
    "    #     print(text[:50])\n",
    "        tokens = word_tokenize(text)\n",
    "        text = ' '.join([word for word in tokens if word not in stopwords_list])\n",
    "    #     print(text[:50])\n",
    "        text = ' '.join([''.join([c if c.isalnum() else ' ' for c in word]) for word in word_tokenize(text)])\n",
    "        text = re.sub(' +', ' ', text)\n",
    "        \n",
    "    #     print(text[:50])\n",
    "        return text.strip()\n",
    "    \n",
    "    except AttributeError:\n",
    "        text = str(text)\n",
    "        return preprocess_text(text)\n",
    "    \n",
    "    except TypeError:\n",
    "        text = text.decode()[1:]\n",
    "        return preprocess(text.strip())\n",
    "\n",
    "def preprocess_ngram_column(df):\n",
    "    return df.ngram.map(lambda x: preprocess_text(x))\n",
    "\n",
    "text = \"I don't like bats, but I do like 39/2 hats!\"\n",
    "clean_text = preprocess_text(text)\n",
    "print(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         date  label                                              ngram  top_n\n",
      "0  2008-08-08      0  b\"Georgia 'downs two Russian warplanes' as cou...      0\n",
      "1  2008-08-11      1  b'Why wont America and Nato help us? If they w...      0\n",
      "2  2008-08-12      0  b'Remember that adorable 9-year-old who sang a...      0\n",
      "3  2008-08-13      0  b' U.S. refuses Israel weapons to attack Iran:...      0\n",
      "4  2008-08-14      1  b'All the experts admit that we should legalis...      0\n",
      "         date  label                                              ngram  top_n\n",
      "0  2008-08-08      0  georgia downs two russian warplanes countries ...      0\n",
      "1  2008-08-11      1  why wont america nato help us wont help us hel...      0\n",
      "2  2008-08-12      0  remember adorable 9 year old sang opening cere...      0\n",
      "3  2008-08-13      0      u s refuses israel weapons attack iran report      0\n",
      "4  2008-08-14      1                   all experts admit legalise drugs      0\n"
     ]
    }
   ],
   "source": [
    "print(X_melt.head())\n",
    "X_melt['ngram'] = preprocess_ngram_column(X_melt)\n",
    "print(X_melt.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = X_melt.ngram.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "georgia downs two russian warplanes countries move brink war\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "print(corpus[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train_corpus, X_test_corpus, y_train_corpus, y_test_corpus = train_test_split(corpus, X_melt.label, random_state=13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# score candidate models for transforming and classifying with headlines\n",
    "from gensim.models import Word2Vec\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn import svm\n",
    "from gensim.sklearn_api import W2VTransformer, D2VTransformer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.pipeline import FeatureUnion, Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, TfidfTransformer, CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression, RidgeClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "tfidf= TfidfVectorizer()\n",
    "cv = CountVectorizer()\n",
    "pipe = Pipeline([\n",
    "    ('vect', CountVectorizer()),\n",
    "    ('tfidf', TfidfTransformer())])\n",
    "w2v = W2VTransformer()\n",
    "d2v = D2VTransformer()\n",
    "# transformers = [('tfidf', tfidf), ('cv', cv), 'w2v', W2VTransformer]\n",
    "transformers = [('cv', cv), \n",
    "                ('tfidf', tfidf), \n",
    "                ('cv2tfidf', pipe)]\n",
    "\n",
    "mNB = MultinomialNB()\n",
    "lr = LogisticRegression(max_iter=10000)\n",
    "rc = RidgeClassifier(max_iter=10000)\n",
    "# gb=GradientBoostingClassifier(random_state=13,\n",
    "#                               subsample=0.8, \n",
    "#                               max_features=\"auto\")\n",
    "sgdc = SGDClassifier()\n",
    "# svc=svm.SVC(random_state=13, \n",
    "#             max_iter=10000, \n",
    "#             kernel='rbf')\n",
    "rf=RandomForestClassifier(random_state=13, \n",
    "                          n_jobs=-1, \n",
    "                          max_features=\"auto\")\n",
    "\n",
    "classifiers = [mNB, lr, rc, sgdc, rf]\n",
    "\n",
    "best_clf, best_score = None, 0\n",
    "\n",
    "for t in transformers:\n",
    "    try:\n",
    "        X = Pipeline([t]).fit_transform(X_train_corpus)\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y_train_corpus, random_state=13)\n",
    "        for clf in classifiers:\n",
    "            try:\n",
    "                clf.fit(X_train, y_train)\n",
    "                score = clf.score(X_test, y_test)\n",
    "                if score > best_score:\n",
    "                    best_score, best_estimator, best_transformer = score, clf, str(t)\n",
    "            except:\n",
    "                print(f'Error classifying with {str(clf)}')\n",
    "                continue\n",
    "    except:\n",
    "        print(f'Error fitting and transforming with {str(t[0])}')\n",
    "        continue\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n",
      "              early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
      "              l1_ratio=0.15, learning_rate='optimal', loss='hinge',\n",
      "              max_iter=1000, n_iter_no_change=5, n_jobs=None, penalty='l2',\n",
      "              power_t=0.5, random_state=None, shuffle=True, tol=0.001,\n",
      "              validation_fraction=0.1, verbose=0, warm_start=False)\n",
      "0.5262762762762763\n",
      "('cv2tfidf', Pipeline(memory=None,\n",
      "         steps=[('vect',\n",
      "                 CountVectorizer(analyzer='word', binary=False,\n",
      "                                 decode_error='strict',\n",
      "                                 dtype=<class 'numpy.int64'>, encoding='utf-8',\n",
      "                                 input='content', lowercase=True, max_df=1.0,\n",
      "                                 max_features=None, min_df=1,\n",
      "                                 ngram_range=(1, 1), preprocessor=None,\n",
      "                                 stop_words=None, strip_accents=None,\n",
      "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "                                 tokenizer=None, vocabulary=None)),\n",
      "                ('tfidf',\n",
      "                 TfidfTransformer(norm='l2', smooth_idf=True,\n",
      "                                  sublinear_tf=False, use_idf=True))],\n",
      "         verbose=False))\n"
     ]
    }
   ],
   "source": [
    "print(best_estimator)\n",
    "print(best_score)\n",
    "print(best_transformer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 128 candidates, totalling 640 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 48 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 104 tasks      | elapsed:   22.7s\n",
      "[Parallel(n_jobs=-1)]: Done 354 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 640 out of 640 | elapsed:  2.1min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: 0.535\n",
      "Best parameters set:\n",
      "\tcv__max_df: 0.75\n",
      "\tcv__ngram_range: (3, 6)\n",
      "\tsgdc__alpha: 1e-06\n",
      "\tsgdc__penalty: 'l2'\n"
     ]
    }
   ],
   "source": [
    "# tune hyperparameters for the best scoring candidate encoder\n",
    "pipeline = Pipeline([\n",
    "    ('cv', CountVectorizer()),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('sgdc', SGDClassifier()),\n",
    "])\n",
    "\n",
    "parameters = {\n",
    "    'cv__max_df': (0.25, 0.5, 0.75, 1.0),\n",
    "    'cv__ngram_range': ((1, 1), (1, 2), (1,3), (1,4), (2,4), (2,5), (3,6), (2,7)),\n",
    "    'sgdc__alpha': (0.00001, 0.000001),\n",
    "    'sgdc__penalty': ('l2', 'elasticnet'),\n",
    "}\n",
    "\n",
    "\n",
    "text_gs = GridSearchCV(pipeline, parameters, n_jobs=-1, verbose=1)\n",
    "\n",
    "text_gs.fit(X_train_corpus, y_train_corpus)\n",
    "\n",
    "print(\"Best score: %0.3f\" % text_gs.best_score_)\n",
    "print(\"Best parameters set:\")\n",
    "best_parameters = text_gs.best_estimator_.get_params()\n",
    "for param_name in sorted(parameters.keys()):\n",
    "    print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 0 0 1 1 1 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "print(text_gs.best_estimator_.predict(corpus[0:10]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 1989 entries, 2008-08-08 to 2016-07-01\n",
      "Data columns (total 25 columns):\n",
      " #   Column       Non-Null Count  Dtype\n",
      "---  ------       --------------  -----\n",
      " 0   (ngram, 0)   1989 non-null   int64\n",
      " 1   (ngram, 1)   1989 non-null   int64\n",
      " 2   (ngram, 2)   1989 non-null   int64\n",
      " 3   (ngram, 3)   1989 non-null   int64\n",
      " 4   (ngram, 4)   1989 non-null   int64\n",
      " 5   (ngram, 5)   1989 non-null   int64\n",
      " 6   (ngram, 6)   1989 non-null   int64\n",
      " 7   (ngram, 7)   1989 non-null   int64\n",
      " 8   (ngram, 8)   1989 non-null   int64\n",
      " 9   (ngram, 9)   1989 non-null   int64\n",
      " 10  (ngram, 10)  1989 non-null   int64\n",
      " 11  (ngram, 11)  1989 non-null   int64\n",
      " 12  (ngram, 12)  1989 non-null   int64\n",
      " 13  (ngram, 13)  1989 non-null   int64\n",
      " 14  (ngram, 14)  1989 non-null   int64\n",
      " 15  (ngram, 15)  1989 non-null   int64\n",
      " 16  (ngram, 16)  1989 non-null   int64\n",
      " 17  (ngram, 17)  1989 non-null   int64\n",
      " 18  (ngram, 18)  1989 non-null   int64\n",
      " 19  (ngram, 19)  1989 non-null   int64\n",
      " 20  (ngram, 20)  1989 non-null   int64\n",
      " 21  (ngram, 21)  1989 non-null   int64\n",
      " 22  (ngram, 22)  1989 non-null   int64\n",
      " 23  (ngram, 23)  1989 non-null   int64\n",
      " 24  (ngram, 24)  1989 non-null   int64\n",
      "dtypes: int64(25)\n",
      "memory usage: 404.0+ KB\n",
      "1989\n",
      "1989\n",
      "<class 'numpy.int64'> <class 'int'>\n"
     ]
    }
   ],
   "source": [
    "final_X = X_melt.copy().drop('label',axis=1)\n",
    "# print(final_X.head())\n",
    "# final_X.set_index('date',inplace=True,drop=True)\n",
    "final_X.ngram = text_gs.best_estimator_.predict(corpus)\n",
    "final_X = final_X.pivot(index='date', columns='top_n')\n",
    "# print(final_X.info())\n",
    "y = text_stock_df.Label\n",
    "# print(y.describe())\n",
    "# print(final_X.info())\n",
    "final_X.info()\n",
    "weights = [1/i for i in range(1,26)]\n",
    "votes = final_X.mean(axis=1)\n",
    "votes_binary = [round(x) for x in votes]\n",
    "print(len(votes_binary))\n",
    "print(len(y))\n",
    "print(type(y[0]), type(votes_binary[0]))\n",
    "cr = classification_report(y, votes_binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       924\n",
      "           1       1.00      1.00      1.00      1065\n",
      "\n",
      "    accuracy                           1.00      1989\n",
      "   macro avg       1.00      1.00      1.00      1989\n",
      "weighted avg       1.00      1.00      1.00      1989\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(cr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# score candidates with headline votes for final classifier\n",
    "classifiers = [mNB, lr, rc, sgdc, rf]\n",
    "\n",
    "best_clf, best_score = None, 0\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(final_X, y, test_size=0.3, stratify=y, random_state=13)\n",
    "for clf in classifiers:\n",
    "    clf.fit(X_train, y_train)\n",
    "    score = clf.score(X_test, y_test)\n",
    "    if score > best_score:\n",
    "        best_score, best_estimator = score, clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
      "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
      "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
      "                   warm_start=False)\n"
     ]
    }
   ],
   "source": [
    "print(best_score)\n",
    "print(best_estimator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 30 folds for each of 40 candidates, totalling 1200 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 48 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 149 tasks      | elapsed:    0.9s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: 1.000\n",
      "Best parameters set:\n",
      "\tC: 100\n",
      "\tpenalty: 'l2'\n",
      "\tsolver: 'newton-cg'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 846 tasks      | elapsed:    3.1s\n",
      "[Parallel(n_jobs=-1)]: Done 1200 out of 1200 | elapsed:    3.1s finished\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "lr = LogisticRegression()\n",
    "solvers = ['newton-cg', 'lbfgs', 'liblinear', 'saga']\n",
    "penalty = ['l2','elasticnet']\n",
    "c_values = [100, 10, 1.0, 0.1, 0.01]\n",
    "param_grid = dict(solver=solvers,penalty=penalty,C=c_values)\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=13)\n",
    "fin_gs = GridSearchCV(lr, param_grid, cv=cv, n_jobs=-1, scoring='accuracy', error_score=0, verbose=1)\n",
    "grid_res = fin_gs.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best score: %0.3f\" % fin_gs.best_score_)\n",
    "print(\"Best parameters set:\")\n",
    "best_parameters = fin_gs.best_estimator_.get_params()\n",
    "for param_name in sorted(param_grid.keys()):\n",
    "    print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report on training set\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       693\n",
      "           1       1.00      1.00      1.00       798\n",
      "\n",
      "    accuracy                           1.00      1491\n",
      "   macro avg       1.00      1.00      1.00      1491\n",
      "weighted avg       1.00      1.00      1.00      1491\n",
      "\n",
      "Classification report on test set\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       231\n",
      "           1       1.00      1.00      1.00       267\n",
      "\n",
      "    accuracy                           1.00       498\n",
      "   macro avg       1.00      1.00      1.00       498\n",
      "weighted avg       1.00      1.00      1.00       498\n",
      "\n",
      "[1.0, 1.0, 1.0]\n",
      "[1.0, 1.0, 1.0]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "def plot_classification_report(cr, title='Classification report ', with_avg_total=False, cmap=plt.cm.Blues):\n",
    "\n",
    "    lines = cr.split('\\n')\n",
    "\n",
    "    classes = []\n",
    "    plotMat = []\n",
    "    for line in lines[2 : (len(lines) - 3)]:\n",
    "        #print(line)\n",
    "        t = line.split()\n",
    "        # print(t)\n",
    "        if len(t)==0:\n",
    "            break\n",
    "        classes.append(t[0])\n",
    "        v = [float(x) for x in t[1: len(t) - 1]]\n",
    "        print(v)\n",
    "        plotMat.append(v)\n",
    "\n",
    "    if with_avg_total:\n",
    "        aveTotal = lines[len(lines) - 1].split()\n",
    "        classes.append('avg/total')\n",
    "        vAveTotal = [float(x) for x in t[1:len(aveTotal) - 1]]\n",
    "        plotMat.append(vAveTotal)\n",
    "\n",
    "\n",
    "    plt.imshow(plotMat, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    x_tick_marks = np.arange(3)\n",
    "    y_tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(x_tick_marks, ['precision', 'recall', 'f1-score'], rotation=45)\n",
    "    plt.yticks(y_tick_marks, classes)\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('Classes')\n",
    "    plt.xlabel('Measures')\n",
    "\n",
    "best_model = fin_gs.best_estimator_\n",
    "y_train_pred = best_model.predict(X_train)\n",
    "y_test_pred = best_model.predict(X_test)\n",
    "cr_train = classification_report(y_train, y_train_pred)\n",
    "cr_test = classification_report(y_test, y_test_pred)\n",
    "print(\"Classification report on training set\")\n",
    "print(cr_train)\n",
    "print(\"Classification report on test set\")\n",
    "# plot_classification_report(cr_train)\n",
    "print(cr_test)\n",
    "plot_classification_report(cr_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROCAUC score: 0.5\n",
      "Accuracy score: 0.536144578313253\n",
      "F1 score: 0.6980392156862745\n",
      "ROCAUC score: 1.0\n",
      "Accuracy score: 1.0\n",
      "F1 score: 1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score, accuracy_score, f1_score\n",
    "base_preds = pd.Series([1]*len(y_test))\n",
    "\n",
    "for preds in [base_preds, y_test_pred]:\n",
    "    print('ROCAUC score:',roc_auc_score(y_test, preds))\n",
    "    print('Accuracy score:',accuracy_score(y_test, preds))\n",
    "    print('F1 score:',f1_score(y_test, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
