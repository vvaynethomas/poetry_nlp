{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "482594c7-a937-42e3-bee4-b458380c8a26",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "import sys\n",
    "from nltk.tokenize import RegexpTokenizer, sent_tokenize, word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, LSTM\n",
    "from keras.utils import np_utils\n",
    "from keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8b08a40b-5db2-4b06-983e-ab735ae06694",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('poetry_corpus.pkl', 'rb') as f:\n",
    "    corpus = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5b60c455-bccb-4692-b8fb-832e0e0f3ccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "poems_in_lines = [poem.splitlines() for poem in corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "25506942-1f90-4ee2-b485-42b889b8010f",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_in_lines = [line for poem in poems_in_lines for line in poem]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7735bf6c-2131-44d9-8de0-34448ecd15f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Dear Writers, I’m compiling the first in what I hope is a series of publications I’m calling artists among artists. The theme for issue 1 is “Faggot Dinosaur.” I hope to hear from you! Thank you and best wishes.'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_in_lines[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07a5d3e8-d42d-4aee-9008-25ceeab1c0a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string, re\n",
    "from nltk.corpus import words\n",
    "import multiprocessing as mp\n",
    "def clean_text(text):\n",
    "    if len(sent_tokenize(text)) > 1:\n",
    "        return ''\n",
    "    text = text.lower()\n",
    "    text = text.replace('\\%','')\n",
    "    text = re.sub('\\[.*?\\]', '', text)\n",
    "    text = re.sub('https?://\\S+|www\\.\\S+', '', text)\n",
    "    text = re.sub('<.*?>+', '', text)\n",
    "    text = re.sub('[%s]' % re.escape(string.punctuation), '', text)\n",
    "    text = re.sub('\\n', ' ', text)\n",
    "    text = re.sub('\\w*\\d\\w*', '', text)\n",
    "    text = \" \".join(filter(lambda x:x[0]!=\"@\", text.split()))\n",
    "    return text\n",
    "\n",
    "with mp.Pool(processes=mp.cpu_count()-1) as pool:\n",
    "    clean_corpus = pool.map(clean_text, corpus_in_lines)\n",
    "# p = Process(target=clean_text, args=)\n",
    "# clean_corpus = Parallel()(delayed(clean_text)(line) for line in corpus_in_lines)\n",
    "# clean_corpus = list(map(clean_text, corpus_in_lines))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf9a87f9-c0f7-466d-9a9a-b542b2aabb4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_corpus_lines = [line for line in clean_corpus if len(word_tokenize(line)) > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "10e4cf02-6fd3-4811-b32d-95fb4bc0ccbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i think that i shall never fear\n"
     ]
    }
   ],
   "source": [
    "print(clean_corpus_lines[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8885f52b-d176-4364-8a56-5c4e6df9c1ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "139400\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "tokenizer = Tokenizer(num_words=5)\n",
    "tokenizer.fit_on_texts(clean_corpus_lines)\n",
    "# input_sequences = tokenizer.texts_to_sequences(corpus_lines)\n",
    "total_words = len(tokenizer.word_index) + 1\n",
    "print(total_words)\n",
    "input_sequences = []\n",
    "for line in corpus_lines:\n",
    "    token_list = tokenizer.texts_to_sequences([line])[0]\n",
    "    for i in range(1, len(token_list)):\n",
    "        n_gram_sequence = token_list[:i+1]\n",
    "        input_sequences.append(n_gram_sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4293ca3d-d842-451f-8bfa-65d58212b76f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "word_df = pd.DataFrame.from_dict(tokenizer.word_index, orient='index', columns=['count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0909f69a-9af2-4d8c-9060-fc3d04e0fa37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     count\n",
      "the      1\n",
      "and      2\n",
      "of       3\n",
      "a        4\n",
      "to       5\n",
      "                 count\n",
      "protoplanetary  139395\n",
      "moogoogaipan    139396\n",
      "nottooold       139397\n",
      "gooing          139398\n",
      "morninga        139399\n"
     ]
    }
   ],
   "source": [
    "print(word_df.head())\n",
    "print(word_df.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "852f301c-ec7b-4fc5-a65f-8a9691f308fe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
