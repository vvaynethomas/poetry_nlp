{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c762842c-965e-4440-b4e4-086bb214f117",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas(desc=\"progress-bar\")\n",
    "from gensim.models import Doc2Vec\n",
    "from sklearn import utils\n",
    "from sklearn.model_selection import train_test_split\n",
    "import gensim\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from gensim.models.doc2vec import TaggedDocument\n",
    "import re\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9944ae8d-82bf-4ce7-b7fa-4f9858c7c7e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load pickles\n",
    "with open('clean_df.pkl', 'rb') as f:\n",
    "    clean_poem_df = pickle.load(f)\n",
    "    \n",
    "with open('clean_line_df.pkl', 'rb') as g:\n",
    "    clean_line_df = pickle.load(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "939ffbc9-aab3-40d6-8b56-e5738f8489bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 15157 entries, 1 to 15651\n",
      "Data columns (total 8 columns):\n",
      " #   Column             Non-Null Count  Dtype   \n",
      "---  ------             --------------  -----   \n",
      " 0   author             15157 non-null  category\n",
      " 1   title              15157 non-null  object  \n",
      " 2   content            15157 non-null  object  \n",
      " 3   line               15157 non-null  object  \n",
      " 4   length_in_lines    15157 non-null  int64   \n",
      " 5   lexical_diversity  15157 non-null  float64 \n",
      " 6   words              15157 non-null  object  \n",
      " 7   id                 15157 non-null  int64   \n",
      "dtypes: category(1), float64(1), int64(2), object(4)\n",
      "memory usage: 1.1+ MB\n"
     ]
    }
   ],
   "source": [
    "clean_poem_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "65c51b43-bd38-4c88-9015-81478b20222c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "def prep_list(text):\n",
    "    while isinstance(text, list):\n",
    "        text = ' '.join([line for line in text])\n",
    "        word_list = text.split()\n",
    "    if isinstance(text, pd.Series):\n",
    "        word_list = word_tokenize(' '.join())\n",
    "    else:\n",
    "        word_list = word_tokenize(text)\n",
    "    return word_list\n",
    "\n",
    "poems_in_words = clean_poem_df.line.map(prep_list)\n",
    "clean_poem_df['words'] = poems_in_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "e57f7f5d-edb8-4a40-b2ae-43c724d0365d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('poems_in_words.pkl', 'wb') as f:\n",
    "    pickle.dump(poems_in_words, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "907b9c97-743e-4f47-96e0-f04ae906ce06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15157\n",
      "['philosophic', 'in', 'its', 'complex', 'ovoid', 'emptiness', 'a', 'skillful', 'pundit', 'coined', 'it', 'as', 'a', 'sort', 'of', 'stopgap', 'doorstop', 'for', 'those', 'quaint', 'equations', 'romans', 'never', 'dreamt', 'of', 'in', 'form', 'completely', 'clever', 'and', 'discrete—a', 'mirror', 'come', 'unsilvered', 'loose', 'watch', 'face', 'without', 'the', 'works', 'a', 'hollowed', 'globe', 'from', 'tip', 'to', 'toe', 'unbroken', 'it', 'evades', 'the', 'grappling', 'hooks', 'of', 'mass', 'tilts', 'the', 'thin', 'rim', 'of', 'no', 'thing', 'remains', 'embryonic', 'sum', 'noncogito'] 1\n"
     ]
    }
   ],
   "source": [
    "elements = list(clean_poem_df.words)\n",
    "ids = [str(i) for i in clean_poem_df.index]\n",
    "print(len(ids))\n",
    "print(elements[0], ids[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "7f603ca9-41ab-4b71-a717-c1eb43fb272d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tagged_poems = [TaggedDocument(element,[i]) for i, element in enumerate(clean_poem_df.words.values)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "64e4468d-12d6-4e44-8b6b-d89fba87295a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TaggedDocument(words=['philosophic', 'in', 'its', 'complex', 'ovoid', 'emptiness', 'a', 'skillful', 'pundit', 'coined', 'it', 'as', 'a', 'sort', 'of', 'stopgap', 'doorstop', 'for', 'those', 'quaint', 'equations', 'romans', 'never', 'dreamt', 'of', 'in', 'form', 'completely', 'clever', 'and', 'discrete—a', 'mirror', 'come', 'unsilvered', 'loose', 'watch', 'face', 'without', 'the', 'works', 'a', 'hollowed', 'globe', 'from', 'tip', 'to', 'toe', 'unbroken', 'it', 'evades', 'the', 'grappling', 'hooks', 'of', 'mass', 'tilts', 'the', 'thin', 'rim', 'of', 'no', 'thing', 'remains', 'embryonic', 'sum', 'noncogito'], tags=[0])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagged_poems[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "fbd6b60d-c08b-4ce1-98b5-862abc998528",
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "cores = multiprocessing.cpu_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "9ce6e5a9-b222-48f7-9953-9bdb42916354",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15157/15157 [00:00<00:00, 2525948.26it/s]\n"
     ]
    }
   ],
   "source": [
    "model_dbow = Doc2Vec(vector_size = 2000,min_count = 0, dm = 0,\n",
    "                     alpha=0.025, min_alpha=-0.0001, workers=cores)\n",
    "model_dbow.build_vocab([x for x in tqdm(tagged_poems)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "1e3702cd-80da-4e1d-b070-f0b6b7f7ca4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15157"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_dbow.corpus_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "5d97e8cb-a7d6-41f7-a505-ae291880d8eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15157/15157 [00:00<00:00, 3032776.73it/s]\n",
      "100%|██████████| 15157/15157 [00:00<00:00, 3032632.05it/s]\n",
      "100%|██████████| 15157/15157 [00:00<00:00, 3030463.62it/s]\n",
      "100%|██████████| 15157/15157 [00:00<00:00, 3030897.05it/s]\n",
      "100%|██████████| 15157/15157 [00:00<00:00, 2526048.62it/s]\n",
      "100%|██████████| 15157/15157 [00:00<00:00, 2526149.00it/s]\n",
      "100%|██████████| 15157/15157 [00:00<00:00, 2527153.19it/s]\n",
      "100%|██████████| 15157/15157 [00:00<00:00, 2526349.77it/s]\n",
      "100%|██████████| 15157/15157 [00:00<00:00, 3031764.31it/s]\n",
      "100%|██████████| 15157/15157 [00:00<00:00, 3031330.62it/s]\n",
      "100%|██████████| 15157/15157 [00:00<00:00, 3032053.50it/s]\n",
      "100%|██████████| 15157/15157 [00:00<00:00, 3031475.17it/s]\n",
      "100%|██████████| 15157/15157 [00:00<00:00, 3031330.62it/s]\n",
      "100%|██████████| 15157/15157 [00:00<00:00, 3032632.05it/s]\n",
      "100%|██████████| 15157/15157 [00:00<00:00, 3031330.62it/s]\n",
      "100%|██████████| 15157/15157 [00:00<00:00, 2526048.62it/s]\n",
      "100%|██████████| 15157/15157 [00:00<00:00, 3031475.17it/s]\n",
      "100%|██████████| 15157/15157 [00:00<00:00, 2525847.90it/s]\n",
      "100%|██████████| 15157/15157 [00:00<00:00, 3031041.56it/s]\n",
      "100%|██████████| 15157/15157 [00:00<00:00, 2526249.38it/s]\n",
      "100%|██████████| 15157/15157 [00:00<00:00, 2526249.38it/s]\n",
      "100%|██████████| 15157/15157 [00:00<00:00, 3032053.50it/s]\n",
      "100%|██████████| 15157/15157 [00:00<00:00, 2526249.38it/s]\n",
      "100%|██████████| 15157/15157 [00:00<00:00, 3031619.73it/s]\n",
      "100%|██████████| 15157/15157 [00:00<00:00, 3030752.56it/s]\n",
      "100%|██████████| 15157/15157 [00:00<00:00, 3032198.12it/s]\n",
      "100%|██████████| 15157/15157 [00:00<00:00, 3031475.17it/s]\n",
      "100%|██████████| 15157/15157 [00:00<00:00, 2526651.00it/s]\n",
      "100%|██████████| 15157/15157 [00:00<00:00, 3031186.08it/s]\n",
      "100%|██████████| 15157/15157 [00:00<00:00, 3031908.90it/s]\n",
      "100%|██████████| 15157/15157 [00:00<00:00, 3031475.17it/s]\n",
      "100%|██████████| 15157/15157 [00:00<00:00, 3030897.05it/s]\n",
      "100%|██████████| 15157/15157 [00:00<00:00, 3031908.90it/s]\n",
      "100%|██████████| 15157/15157 [00:00<00:00, 3031475.17it/s]\n",
      "100%|██████████| 15157/15157 [00:00<00:00, 3032342.75it/s]\n",
      "100%|██████████| 15157/15157 [00:00<00:00, 3031475.17it/s]\n",
      "100%|██████████| 15157/15157 [00:00<00:00, 2525245.91it/s]\n",
      "100%|██████████| 15157/15157 [00:00<00:00, 2527555.09it/s]\n",
      "100%|██████████| 15157/15157 [00:00<00:00, 3031619.73it/s]\n",
      "100%|██████████| 15157/15157 [00:00<00:00, 2525747.55it/s]\n",
      "100%|██████████| 15157/15157 [00:00<00:00, 3030030.30it/s]\n",
      "100%|██████████| 15157/15157 [00:00<00:00, 3031330.62it/s]\n",
      "100%|██████████| 15157/15157 [00:00<00:00, 2526550.58it/s]\n",
      "100%|██████████| 15157/15157 [00:00<00:00, 3032487.39it/s]\n",
      "100%|██████████| 15157/15157 [00:00<00:00, 3031908.90it/s]\n",
      "100%|██████████| 15157/15157 [00:00<00:00, 3033500.30it/s]\n",
      "100%|██████████| 15157/15157 [00:00<00:00, 2526048.62it/s]\n",
      "100%|██████████| 15157/15157 [00:00<00:00, 3031475.17it/s]\n",
      "100%|██████████| 15157/15157 [00:00<00:00, 3030608.08it/s]\n",
      "100%|██████████| 15157/15157 [00:00<00:00, 3030030.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 2min 51s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for epoch in range(50):\n",
    "    model_dbow.train(utils.shuffle([x for x in tqdm(tagged_poems)]), total_examples=model_dbow.corpus_count, epochs=1)\n",
    "    model_dbow.alpha -= 0.002\n",
    "    model_dbow.min_alpha = model_dbow.alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "80a74d55-3a80-4e47-9e95-83be05edb2c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15157, 2000)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_dbow.docvecs.vectors_docs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "9b82ae62-a19e-4ffa-beee-9cf4327e8aef",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dbow.save(\"poem_doc2vec_dbow2000.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "01b00c0d-ecf1-4dda-8423-3ac05d766e5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 2000)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "0cd905b4-f999-46c2-88d0-f13e1becdf85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('unsorted', 0.09931951761245728),\n",
       " ('lycaeides', 0.09291273355484009),\n",
       " ('scotfree', 0.0894961878657341),\n",
       " ('fellowmen', 0.08882109820842743),\n",
       " ('hellion', 0.08766721189022064),\n",
       " ('sheers', 0.08732171356678009),\n",
       " ('cameraman', 0.08711902797222137),\n",
       " ('allureth', 0.086117222905159),\n",
       " ('abided', 0.08551956713199615),\n",
       " ('extenuating', 0.08515588939189911)]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_dbow.wv.most_similar('he')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "1004c02a-1e27-44a8-b600-8e0157ad9328",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Doc2Vec' object has no attribute 'vectors'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-72-f6ba472a296b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# from gensim.models import KeyeVectors\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# dictionary = KeyedVectors.laod_word2vec_format()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mdoc_tags\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_dbow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvectors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdoctags\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel_dbow\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdoc_tags\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'Doc2Vec' object has no attribute 'vectors'"
     ]
    }
   ],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "# from gensim.models import KeyeVectors\n",
    "# dictionary = KeyedVectors.laod_word2vec_format()\n",
    "doc_tags = list(model_dbow.vectors.doctags.keys())\n",
    "X = model_dbow[doc_tags]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fea7c0f-1909-4356-96a7-3329cd4fe820",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
