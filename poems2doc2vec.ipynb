{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c762842c-965e-4440-b4e4-086bb214f117",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas(desc=\"progress-bar\")\n",
    "from gensim.models import Doc2Vec\n",
    "from sklearn import utils\n",
    "from sklearn.model_selection import train_test_split\n",
    "import gensim\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from gensim.models.doc2vec import TaggedDocument\n",
    "import re\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9944ae8d-82bf-4ce7-b7fa-4f9858c7c7e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load df\n",
    "with open('tagged_poems_df.pkl', 'rb') as f:\n",
    "    clean_poem_df = pickle.load(f)\n",
    "    \n",
    "with open('tagged_lines_df.pkl', 'rb') as g:\n",
    "    clean_line_df = pickle.load(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "939ffbc9-aab3-40d6-8b56-e5738f8489bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 14779 entries, 1 to 15651\n",
      "Data columns (total 10 columns):\n",
      " #   Column             Non-Null Count  Dtype   \n",
      "---  ------             --------------  -----   \n",
      " 0   author             14779 non-null  category\n",
      " 1   title              14779 non-null  object  \n",
      " 2   content            14779 non-null  object  \n",
      " 3   line               14779 non-null  object  \n",
      " 4   length_in_lines    14779 non-null  int64   \n",
      " 5   lexical_diversity  14779 non-null  float64 \n",
      " 6   words              14779 non-null  object  \n",
      " 7   word_lengths       14779 non-null  object  \n",
      " 8   max_word_length    14779 non-null  int64   \n",
      " 9   pos_tags           14779 non-null  object  \n",
      "dtypes: category(1), float64(1), int64(2), object(6)\n",
      "memory usage: 1.2+ MB\n"
     ]
    }
   ],
   "source": [
    "clean_poem_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4b9af55f-c55b-49ad-a72b-d283940b8c68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 411540 entries, 1 to 453771\n",
      "Data columns (total 10 columns):\n",
      " #   Column             Non-Null Count   Dtype   \n",
      "---  ------             --------------   -----   \n",
      " 0   author             411540 non-null  category\n",
      " 1   title              411540 non-null  object  \n",
      " 2   line               411540 non-null  object  \n",
      " 3   line_no            411540 non-null  int64   \n",
      " 4   words              411540 non-null  object  \n",
      " 5   length_in_words    411540 non-null  int64   \n",
      " 6   lexical_diversity  411540 non-null  float64 \n",
      " 7   word_lengths       411540 non-null  object  \n",
      " 8   max_word_length    411540 non-null  int64   \n",
      " 9   pos_tags           411540 non-null  object  \n",
      "dtypes: category(1), float64(1), int64(3), object(5)\n",
      "memory usage: 32.2+ MB\n"
     ]
    }
   ],
   "source": [
    "clean_line_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fedae42-9547-42ba-b9c2-4313615492e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "907b9c97-743e-4f47-96e0-f04ae906ce06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14779\n",
      "['philosophic', 'in', 'its', 'complex', 'ovoid', 'emptiness', 'a', 'skillful', 'pundit', 'coined', 'it', 'as', 'a', 'sort', 'of', 'stopgap', 'doorstop', 'for', 'those', 'quaint', 'equations', 'romans', 'never', 'dreamt', 'of', 'in', 'form', 'completely', 'clever', 'and', 'discretea', 'mirror', 'come', 'unsilvered', 'loose', 'watch', 'face', 'without', 'the', 'works', 'a', 'hollowed', 'globe', 'from', 'tip', 'to', 'toe', 'unbroken', 'it', 'evades', 'the', 'grappling', 'hooks', 'of', 'mass', 'tilts', 'the', 'thin', 'rim', 'of', 'no', 'thing', 'remains', 'embryonic', 'sum', 'non-cogito'] 1\n"
     ]
    }
   ],
   "source": [
    "elements = list(clean_poem_df.words)\n",
    "ids = [str(i) for i in clean_poem_df.index]\n",
    "print(len(ids))\n",
    "print(elements[0], ids[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7f603ca9-41ab-4b71-a717-c1eb43fb272d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tagged_poems = [TaggedDocument(element,[i]) for i, element in enumerate(clean_poem_df.words.values)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "64e4468d-12d6-4e44-8b6b-d89fba87295a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TaggedDocument(words=['philosophic', 'in', 'its', 'complex', 'ovoid', 'emptiness', 'a', 'skillful', 'pundit', 'coined', 'it', 'as', 'a', 'sort', 'of', 'stopgap', 'doorstop', 'for', 'those', 'quaint', 'equations', 'romans', 'never', 'dreamt', 'of', 'in', 'form', 'completely', 'clever', 'and', 'discretea', 'mirror', 'come', 'unsilvered', 'loose', 'watch', 'face', 'without', 'the', 'works', 'a', 'hollowed', 'globe', 'from', 'tip', 'to', 'toe', 'unbroken', 'it', 'evades', 'the', 'grappling', 'hooks', 'of', 'mass', 'tilts', 'the', 'thin', 'rim', 'of', 'no', 'thing', 'remains', 'embryonic', 'sum', 'non-cogito'], tags=[0])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagged_poems[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fbd6b60d-c08b-4ce1-98b5-862abc998528",
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "cores = multiprocessing.cpu_count()-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9ce6e5a9-b222-48f7-9953-9bdb42916354",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14779/14779 [00:00<00:00, 2956719.24it/s]\n"
     ]
    }
   ],
   "source": [
    "model_dbow = Doc2Vec(vector_size = 500, min_count = 0, dm = 0,\n",
    "                     alpha=0.025, min_alpha=-0.0001, workers=cores)\n",
    "model_dbow.build_vocab([x for x in tqdm(tagged_poems)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1e3702cd-80da-4e1d-b070-f0b6b7f7ca4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14779"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_dbow.corpus_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5d97e8cb-a7d6-41f7-a505-ae291880d8eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14779/14779 [00:00<00:00, 2957283.47it/s]\n",
      "100%|██████████| 14779/14779 [00:00<00:00, 2956437.20it/s]\n",
      "100%|██████████| 14779/14779 [00:00<00:00, 2463834.76it/s]\n",
      "100%|██████████| 14779/14779 [00:00<00:00, 2956437.20it/s]\n",
      "100%|██████████| 14779/14779 [00:00<00:00, 2955450.50it/s]\n",
      "100%|██████████| 14779/14779 [00:00<00:00, 2955450.50it/s]\n",
      "100%|██████████| 14779/14779 [00:00<00:00, 2956719.24it/s]\n",
      "100%|██████████| 14779/14779 [00:00<00:00, 2955450.50it/s]\n",
      "100%|██████████| 14779/14779 [00:00<00:00, 2955168.71it/s]\n",
      "100%|██████████| 14779/14779 [00:00<00:00, 2956437.20it/s]\n",
      "100%|██████████| 14779/14779 [00:00<00:00, 2956296.20it/s]\n",
      "100%|██████████| 14779/14779 [00:00<00:00, 2955591.42it/s]\n",
      "100%|██████████| 14779/14779 [00:00<00:00, 2956719.24it/s]\n",
      "100%|██████████| 14779/14779 [00:00<00:00, 2956719.24it/s]\n",
      "100%|██████████| 14779/14779 [00:00<00:00, 2957989.06it/s]\n",
      "100%|██████████| 14779/14779 [00:00<00:00, 2957001.33it/s]\n",
      "100%|██████████| 14779/14779 [00:00<00:00, 2957283.47it/s]\n",
      "100%|██████████| 14779/14779 [00:00<00:00, 2956860.28it/s]\n",
      "100%|██████████| 14779/14779 [00:00<00:00, 2956578.21it/s]\n",
      "100%|██████████| 14779/14779 [00:00<00:00, 2956014.25it/s]\n",
      "100%|██████████| 14779/14779 [00:00<00:00, 2956437.20it/s]\n",
      "100%|██████████| 14779/14779 [00:00<00:00, 2957565.67it/s]\n",
      "100%|██████████| 14779/14779 [00:00<00:00, 2956437.20it/s]\n",
      "100%|██████████| 14779/14779 [00:00<00:00, 2956014.25it/s]\n",
      "100%|██████████| 14779/14779 [00:00<00:00, 2956437.20it/s]\n",
      "100%|██████████| 14779/14779 [00:00<00:00, 2463149.44it/s]\n",
      "100%|██████████| 14779/14779 [00:00<00:00, 2463345.21it/s]\n",
      "100%|██████████| 14779/14779 [00:00<00:00, 2954746.12it/s]\n",
      "100%|██████████| 14779/14779 [00:00<00:00, 2957706.79it/s]\n",
      "100%|██████████| 14779/14779 [00:00<00:00, 2957001.33it/s]\n",
      "100%|██████████| 14779/14779 [00:00<00:00, 2960107.87it/s]\n",
      "100%|██████████| 14779/14779 [00:00<00:00, 2956437.20it/s]\n",
      "100%|██████████| 14779/14779 [00:00<00:00, 2957001.33it/s]\n",
      "100%|██████████| 14779/14779 [00:00<00:00, 2955873.29it/s]\n",
      "100%|██████████| 14779/14779 [00:00<00:00, 2463541.01it/s]\n",
      "100%|██████████| 14779/14779 [00:00<00:00, 2464030.64it/s]\n",
      "100%|██████████| 14779/14779 [00:00<00:00, 2956437.20it/s]\n",
      "100%|██████████| 14779/14779 [00:00<00:00, 3694577.35it/s]\n",
      "100%|██████████| 14779/14779 [00:00<00:00, 2957424.56it/s]\n",
      "100%|██████████| 14779/14779 [00:00<00:00, 2956155.22it/s]\n",
      "100%|██████████| 14779/14779 [00:00<00:00, 2956578.21it/s]\n",
      "100%|██████████| 14779/14779 [00:00<00:00, 2956437.20it/s]\n",
      "100%|██████████| 14779/14779 [00:00<00:00, 2958412.58it/s]\n",
      "100%|██████████| 14779/14779 [00:00<00:00, 2955732.35it/s]\n",
      "100%|██████████| 14779/14779 [00:00<00:00, 2955873.29it/s]\n",
      "100%|██████████| 14779/14779 [00:00<00:00, 2955591.42it/s]\n",
      "100%|██████████| 14779/14779 [00:00<00:00, 2956860.28it/s]\n",
      "100%|██████████| 14779/14779 [00:00<00:00, 2956014.25it/s]\n",
      "100%|██████████| 14779/14779 [00:00<00:00, 2956578.21it/s]\n",
      "100%|██████████| 14779/14779 [00:00<00:00, 2957142.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 54s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for epoch in range(50):\n",
    "    model_dbow.train(utils.shuffle([x for x in tqdm(tagged_poems)]), total_examples=model_dbow.corpus_count, epochs=1)\n",
    "    model_dbow.alpha -= 0.002\n",
    "    model_dbow.min_alpha = model_dbow.alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "80a74d55-3a80-4e47-9e95-83be05edb2c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14779, 500)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_dbow.docvecs.vectors_docs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9b82ae62-a19e-4ffa-beee-9cf4327e8aef",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dbow.save(\"poem_doc2vec_dbow500.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01b00c0d-ecf1-4dda-8423-3ac05d766e5f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0cd905b4-f999-46c2-88d0-f13e1becdf85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('counterterrorism', 0.18991439044475555),\n",
       " ('avant', 0.18803800642490387),\n",
       " ('yakutat', 0.1750287115573883),\n",
       " ('replaced', 0.17184962332248688),\n",
       " ('retractable', 0.16939330101013184),\n",
       " ('picardie', 0.16750100255012512),\n",
       " ('haydn', 0.16565947234630585),\n",
       " ('pantalooned', 0.1646561324596405),\n",
       " ('weltgeist&amp', 0.16395975649356842),\n",
       " ('dark-winged', 0.16297659277915955)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_dbow.wv.most_similar('he')\n",
    "model_dbow.wv.most_similar('his')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1004c02a-1e27-44a8-b600-8e0157ad9328",
   "metadata": {},
   "outputs": [],
   "source": [
    "poem_vector=[]\n",
    "\n",
    "t = 1000\n",
    "\n",
    "for i in range(len(poems)):\n",
    "    if i % t == 0:\n",
    "        print(\"poem\", i, \":\", poems[i])\n",
    "        print(\"***\")\n",
    "    poem = poems[i]\n",
    "    poem_vector.append(doc2vec_model.infer_vector(poem))\n",
    "    \n",
    "#save the lines_vector\n",
    "poem_vector_file = \"poem_vector_2000.pkl\"\n",
    "with open(poem_vector_file, 'wb') as f:\n",
    "    pickle.dump((poem_vector), f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fea7c0f-1909-4356-96a7-3329cd4fe820",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
